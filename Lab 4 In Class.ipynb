{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Mode Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation dataset\n",
    "\n",
    "We are using the same 2017 survey trip records for estimation. However, the data has been pre-processed for you to allow for model estimation. The file **'trip17_estimation.csv'** contains all of the observed rows, but also has additional rows for the unchosen alternative by mode. To measure and estimate the relative value of one mode alternative to the others, we need data on those other alternatives, which generally aren't provided in a standard survey. \n",
    "\n",
    "This dataset was generated by duplicating all observed (chosen) trips (total length x) for each mode (m) alternative (once for walk alternatives, once for bike, etc.), to end up with a new dataset that was of length (x)(m). Existing PSRC scripts were used to add travel time, cost, and distance for these trip alternatives, using model outputs. Model outputs report time/cost/distance between all origins and destinations (often called 'skims'), so it's possible to provided measures for all trips, even those that are highly unlikely (like biking from Tacoma to Everett). Some modellers have used other means of attaching these \"skim\" values to alternatives, including Google APIs. There is usually a cost associated with this since API calls are capped, and model skims are readily available, so it was easier to use the old method. However, with more observed data in the world, there are plenty of alternatives becoming available!\n",
    "\n",
    "----\n",
    "\n",
    "## Data dictionary\n",
    "### Modes:\n",
    "- 1: Walk\n",
    "- 2: Bike\n",
    "- 3: SOV (single occupant vehicle)\n",
    "- 4: HOV2 (2 people in a vehicle)\n",
    "- 5: HOV3 (3 or more people in a vehicle)\n",
    "- 6: Transit (including bus and train)\n",
    "- 9: TNC (hired rideshare vehicles like Uber, Lyft)\n",
    "\n",
    "### Sociodemographics and Land Use:\n",
    "Same as past codebook unless otherwise noted\n",
    "- choice: 0/1 for if record represents observed choice data\n",
    "- hh_density_o: households/ft^2 in trip's origin TAZ\n",
    "- emp_density_o: total employees/ft^2 in trip's origin TAZ\n",
    "- college_density_o: college students/ft^2 in trip's origin TAZ\n",
    "- gradeschool_density_o: gradeschool students/ft^2 in trip's origin TAZ\n",
    "- dist_lbus: distance to transit in miles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pylogit\n",
    "\n",
    "There are multiple libraries that can be used to estimate choice models in Python, including:\n",
    "- [statsmodels](https://www.statsmodels.org/stable/index.html)\n",
    "- [pylogit](https://github.com/timothyb0912/pylogit)\n",
    "- [choicemodels (built partially off pylogit)](https://github.com/UDST/choicemodels)\n",
    "- [biogeme](http://biogeme.epfl.ch/examples_swissmetro.html)\n",
    "\n",
    "We will focus on pylogit because it is easier and more flexible to use than statsmodels, and more developed than choicemodels, which is still in development. Biogeme is an old tool that is now available in pandas, which is very nice, but the documentation is somewhat lacking. You are welcome to try multiple libraries, but I will only be able to provide direct supply for pylogit.\n",
    "\n",
    "For more information, see: https://github.com/timothyb0912/pylogit/tree/master/examples/notebooks. \n",
    "- You can open HTML notebooks from these links, e.g. https://github.com/timothyb0912/pylogit/blob/master/examples/notebooks/Main%20PyLogit%20Example.ipynb\n",
    "- If interested in nested logit, see example: https://github.com/timothyb0912/pylogit/blob/master/examples/notebooks/Nested%20Logit%20Example--Python%20Biogeme%20benchmark--09NestedLogit.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import the pylogit library\n",
    "import pylogit as pl    # Importing as shortcut \"pl\", similar to pandas imported as \"pd\"\n",
    "from collections import OrderedDict    # a requirement for pylogit specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a list of HBW trips in estimation format\n",
    "\n",
    "df_hbw = pd.read_csv(r'data/trip17_estimation_hbw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhno</th>\n",
       "      <th>pno</th>\n",
       "      <th>mode</th>\n",
       "      <th>opurp</th>\n",
       "      <th>dpurp</th>\n",
       "      <th>deptm</th>\n",
       "      <th>otaz</th>\n",
       "      <th>dtaz</th>\n",
       "      <th>arrtm</th>\n",
       "      <th>trexpfac</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_lbus</th>\n",
       "      <th>hhid</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>vehicle_count</th>\n",
       "      <th>numchildren</th>\n",
       "      <th>numworkers</th>\n",
       "      <th>hhincome_broad</th>\n",
       "      <th>rent_own</th>\n",
       "      <th>res_type</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>119.663798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>119.663798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>119.663798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>119.663798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>119.663798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>17100248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34526</th>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>907</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104494</td>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34527</th>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>907</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104494</td>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34528</th>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>907</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104494</td>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34529</th>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>907</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104494</td>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34530</th>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>907</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104494</td>\n",
       "      <td>17148237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34531 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hhno  pno  mode  opurp  dpurp  deptm  otaz  dtaz  arrtm  \\\n",
       "0      17100248    1     1      1      0      0   327   429      0   \n",
       "1      17100248    1     2      1      0      0   327   429      0   \n",
       "2      17100248    1     3      1      0      0   327   429      0   \n",
       "3      17100248    1     4      1      0      0   327   429      0   \n",
       "4      17100248    1     5      1      0      0   327   429      0   \n",
       "...         ...  ...   ...    ...    ...    ...   ...   ...    ...   \n",
       "34526  17148237    1     3      1      0      0   907   778      0   \n",
       "34527  17148237    1     4      1      0      0   907   778      0   \n",
       "34528  17148237    1     5      1      0      0   907   778      0   \n",
       "34529  17148237    1     6      1      0      0   907   778      0   \n",
       "34530  17148237    1     9      1      0      0   907   778      0   \n",
       "\n",
       "         trexpfac  ... dist_lbus      hhid  hhsize  vehicle_count  \\\n",
       "0      119.663798  ...  0.069752  17100248       1              0   \n",
       "1      119.663798  ...  0.069752  17100248       1              0   \n",
       "2      119.663798  ...  0.069752  17100248       1              0   \n",
       "3      119.663798  ...  0.069752  17100248       1              0   \n",
       "4      119.663798  ...  0.069752  17100248       1              0   \n",
       "...           ...  ...       ...       ...     ...            ...   \n",
       "34526    0.000000  ...  0.104494  17148237       1              1   \n",
       "34527    0.000000  ...  0.104494  17148237       1              1   \n",
       "34528    0.000000  ...  0.104494  17148237       1              1   \n",
       "34529    0.000000  ...  0.104494  17148237       1              1   \n",
       "34530    0.000000  ...  0.104494  17148237       1              1   \n",
       "\n",
       "       numchildren  numworkers  hhincome_broad  rent_own  res_type  intercept  \n",
       "0                0           1            15.0         1         4        1.0  \n",
       "1                0           1            15.0         1         4        1.0  \n",
       "2                0           1            15.0         1         4        1.0  \n",
       "3                0           1            15.0         1         4        1.0  \n",
       "4                0           1            15.0         1         4        1.0  \n",
       "...            ...         ...             ...       ...       ...        ...  \n",
       "34526            0           1            17.5         2         3        1.0  \n",
       "34527            0           1            17.5         2         3        1.0  \n",
       "34528            0           1            17.5         2         3        1.0  \n",
       "34529            0           1            17.5         2         3        1.0  \n",
       "34530            0           1            17.5         2         3        1.0  \n",
       "\n",
       "[34531 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does the trips dataset look like now?\n",
    "df_hbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNL estimation specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using what is called an Ordered Dictionary\n",
    "# Remember that a dictionary looks like this {'key': 'value'}\n",
    "# An ordered dictionary is a special version of this type that keeps the keys in order\n",
    "\n",
    "specification = OrderedDict()\n",
    "names = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('intercept', [1, 2, 4, 5, 6, 9])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the alternative specific constants (ASCs), i.e., the intercepts\n",
    "# Remember that one choice is the baseline (ASC=0)\n",
    "# Leave the chosen baseline mode out of the list of intercept values below\n",
    "# In this case, we are using SOV as the base model - it's common to use the most likely alternative as the base\n",
    "specification[\"intercept\"] = [1, 2, 4, 5, 6, 9]    # these are the mode IDs, excluding 3 for SOV\n",
    "names['intercept'] = ['Walk ASC','Bike ASC', 'HOV2 ASC','HOV3+ ASC','Transit ASC', 'TNC']    # Provide labels\n",
    "\n",
    "specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('intercept',\n",
       "              ['Walk ASC',\n",
       "               'Bike ASC',\n",
       "               'HOV2 ASC',\n",
       "               'HOV3+ ASC',\n",
       "               'Transit ASC',\n",
       "               'TNC']),\n",
       "             ('travtime', ['time all'])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a coefficient for travel time\n",
    "# Note that we are using only a single travel time coefficient across all modes\n",
    "# Lists of lists denote alternatives will share a common coefficient\n",
    "\n",
    "specification['travtime'] = [[1,2,3,4,5,6,9]]    # Note that this is a list inside a list [[]]\n",
    "names['travtime'] = ['time all']\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which columns are used in the estimation\n",
    "custom_alt_id = \"mode_id\"    # Mode columns, must be integer based\n",
    "obs_id_column = \"custom_id\"    # an ID that is unique to each choice (a set of chosen and unchosen alternatives have their own ID)\n",
    "choice_column = \"choice\"    # 0/1 column indicating if that row was the chosen or unchosen alternative\n",
    "\n",
    "# Call the module to create the choice model specification\n",
    "model_1 = pl.create_choice_model(data=df_hbw,    # Note that here's we are specifying the df_hbw dataset\n",
    "                                alt_id_col=custom_alt_id,\n",
    "                                obs_id_col=obs_id_column,\n",
    "                                choice_col=choice_column,\n",
    "                                specification=specification,    # using the basic_specification from above\n",
    "                                model_type=\"MNL\",\n",
    "                                names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pylogit.conditional_logit.MNL at 0x7fc6a05b5c70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -9,595.2829\n",
      "Initial Log-likelihood: -9,595.2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaitlynng/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:527: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  warn('Method %s does not use Hessian information (hess).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.53 seconds.\n",
      "Final log-likelihood: -6,436.4076\n",
      "             parameters  std_err  t_stats  p_values  robust_std_err  \\\n",
      "Walk ASC          0.705    0.074    9.493       0.0           0.127   \n",
      "Bike ASC         -1.554    0.073  -21.240       0.0           0.084   \n",
      "HOV2 ASC         -1.735    0.054  -31.944       0.0           0.054   \n",
      "HOV3+ ASC        -3.433    0.119  -28.871       0.0           0.119   \n",
      "Transit ASC      -0.355    0.036   -9.839       0.0           0.039   \n",
      "TNC              -3.548    0.126  -28.204       0.0           0.126   \n",
      "time all         -0.038    0.002  -23.033       0.0           0.004   \n",
      "\n",
      "             robust_t_stats  robust_p_values  \n",
      "Walk ASC              5.565              0.0  \n",
      "Bike ASC            -18.402              0.0  \n",
      "HOV2 ASC            -31.942              0.0  \n",
      "HOV3+ ASC           -28.870              0.0  \n",
      "Transit ASC          -9.093              0.0  \n",
      "TNC                 -28.204              0.0  \n",
      "time all             -9.896              0.0  \n",
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      choice   No. Observations:                4,933\n",
      "Model:             Multinomial Logit Model   Df Residuals:                    4,926\n",
      "Method:                                MLE   Df Model:                            7\n",
      "Date:                     Mon, 06 Nov 2023   Pseudo R-squ.:                   0.329\n",
      "Time:                             13:25:58   Pseudo R-bar-squ.:               0.328\n",
      "AIC:                            12,886.815   Log-Likelihood:             -6,436.408\n",
      "BIC:                            12,932.341   LL-Null:                    -9,595.283\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Walk ASC        0.7054      0.074      9.493      0.000       0.560       0.851\n",
      "Bike ASC       -1.5545      0.073    -21.240      0.000      -1.698      -1.411\n",
      "HOV2 ASC       -1.7347      0.054    -31.944      0.000      -1.841      -1.628\n",
      "HOV3+ ASC      -3.4333      0.119    -28.871      0.000      -3.666      -3.200\n",
      "Transit ASC    -0.3546      0.036     -9.839      0.000      -0.425      -0.284\n",
      "TNC            -3.5483      0.126    -28.204      0.000      -3.795      -3.302\n",
      "time all       -0.0379      0.002    -23.033      0.000      -0.041      -0.035\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# The code above only generated the template to estimate the model. We still need to execute the actual\n",
    "# maximum likelihood estimation process. \n",
    "\n",
    "# Run the estimation given the specification \"basic_mnl\"\n",
    "\n",
    "# Specify the initial values and method for the optimization.\n",
    "# Note that the value in np.zeros() is the number of coefficients we expect to return, including ASCs\n",
    "# For the basic setup above there are 6 ASC alternatives and 1 travel time variable, for a total of 7\n",
    "# Note that the error result if you get this number wrong will usually give the required value. \n",
    "\n",
    "# Note that here's were using a method called \"fit_mile\" on the object \"basic_mnl,\" which we created above. \n",
    "model_1.fit_mle(np.zeros(7))\n",
    "print(np.round(model_1.summary, 3))    # Make things easier to read\n",
    "\n",
    "# Look at the estimation results\n",
    "print(model_1.get_statsmodels_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing to a new model\n",
    "\n",
    "## Hypothesis test\n",
    "\n",
    "State the null $H_0$ and the alternative hypothesis $H_a$:\n",
    "- $H_0: \\beta(travel time) = \\beta(travel time_x)$ for all of $x$ modes - Model 1\n",
    "- $H_a: \\beta(travel time) \\neq \\beta(travel time_x)$ for all of $x$ modes - Model 2\n",
    "\n",
    "We will reject the null hypothesis ($H_0$) if there is a statistically significant difference between the two models based on the likelihood ratio test.\n",
    "\n",
    "Intuitively, this test is saying that we think there might be differences in the way time is valued across modes. The null is saying that all modes users have a shared time valuation.\n",
    "\n",
    "## Utility equations for Model 2\n",
    "Note that SOV is our base case.\n",
    "- $V(walk) = ASC_{walk} + \\beta(time_{walk}) * TTime_{walk}$\n",
    "- $V(bike) = ASC_{bike} + \\beta(time_{bike}) * TTime_{bike}$\n",
    "- $V(hov2) = ASC_{hov2} + \\beta(time_{hov2}) * TTime_{hov2}$\n",
    "- $V(hov3) = ASC_{hov3} + \\beta(time_{hov3}) * TTime_{hov3}$\n",
    "- $V(transit) = ASC_{transit} + \\beta(time_{transit}) * TTime_{transit}$\n",
    "- $V(tnc) = ASC_{tnc} + \\beta(time_{tnc}) * TTime_{tnc}$\n",
    "- $V(sov) = \\beta(time_{sov}) * TTime_{sov}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using what is called an Ordered Dictionary\n",
    "# Remember that a dictionary looks like this {'key': 'value'}\n",
    "# An ordered dictionary is a special version of this type that keeps the keys in order\n",
    "\n",
    "specification = OrderedDict()\n",
    "names = OrderedDict()\n",
    "\n",
    "# Define the alternative specific constants (ASCs), i.e., the intercepts\n",
    "# Remember that one choice is the baseline (ASC=0)\n",
    "# Leave the chosen baseline mode out of the list of intercept values below\n",
    "# In this case, we are using SOV as the base model - it's common to use the most likely alternative as the base\n",
    "specification[\"intercept\"] = [1, 2, 4, 5, 6, 9]    # these are the mode IDs, excluding 3 for SOV\n",
    "names['intercept'] = ['Walk ASC','Bike ASC', 'HOV2 ASC','HOV3+ ASC','Transit ASC', 'TNC']    # Provide labels\n",
    "\n",
    "# Adding a travel time coefficient for all modes\n",
    "specification['travtime'] = [1,2,3,4,5,6,9]    \n",
    "names['travtime'] = ['time walk','time bike','time sov','time hov2','time hov3', 'time transit','time tnc']\n",
    "\n",
    "# Specify which columns are used in the estimation\n",
    "custom_alt_id = \"mode_id\"    # Mode columns, must be integer based\n",
    "obs_id_column = \"custom_id\"    # an ID that is unique to each choice (a set of chosen and unchosen alternatives have their own ID)\n",
    "choice_column = \"choice\"    # 0/1 column indicating if that row was the chosen or unchosen alternative\n",
    "\n",
    "# Call the module to create the choice model specification\n",
    "model_2 = pl.create_choice_model(data=df_hbw,    # Note that here's we are specifying the df_hbw dataset\n",
    "                                alt_id_col=custom_alt_id,\n",
    "                                obs_id_col=obs_id_column,\n",
    "                                choice_col=choice_column,\n",
    "                                specification=specification,    # using the basic_specification from above\n",
    "                                model_type=\"MNL\",\n",
    "                                names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -9,595.2829\n",
      "Initial Log-likelihood: -9,595.2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaitlynng/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:527: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  warn('Method %s does not use Hessian information (hess).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.53 seconds.\n",
      "Final log-likelihood: -6,250.2121\n",
      "              parameters  std_err  t_stats  p_values  robust_std_err  \\\n",
      "Walk ASC          -0.305    0.113   -2.687     0.007           0.174   \n",
      "Bike ASC          -2.688    0.137  -19.578     0.000           0.153   \n",
      "HOV2 ASC          -0.585    0.132   -4.428     0.000           0.147   \n",
      "HOV3+ ASC         -2.767    0.283   -9.795     0.000           0.319   \n",
      "Transit ASC       -1.311    0.093  -14.071     0.000           0.126   \n",
      "TNC               -2.380    0.302   -7.870     0.000           0.236   \n",
      "time walk         -0.045    0.002  -24.666     0.000           0.005   \n",
      "time bike         -0.061    0.004  -15.101     0.000           0.005   \n",
      "time sov          -0.167    0.010  -17.524     0.000           0.015   \n",
      "time hov2         -0.240    0.012  -19.984     0.000           0.016   \n",
      "time hov3         -0.207    0.019  -11.094     0.000           0.023   \n",
      "time transit      -0.095    0.005  -19.704     0.000           0.007   \n",
      "time tnc          -0.241    0.021  -11.254     0.000           0.019   \n",
      "\n",
      "              robust_t_stats  robust_p_values  \n",
      "Walk ASC              -1.749             0.08  \n",
      "Bike ASC             -17.523             0.00  \n",
      "HOV2 ASC              -3.971             0.00  \n",
      "HOV3+ ASC             -8.684             0.00  \n",
      "Transit ASC          -10.396             0.00  \n",
      "TNC                  -10.093             0.00  \n",
      "time walk             -9.904             0.00  \n",
      "time bike            -13.053             0.00  \n",
      "time sov             -11.473             0.00  \n",
      "time hov2            -14.892             0.00  \n",
      "time hov3             -8.847             0.00  \n",
      "time transit         -14.412             0.00  \n",
      "time tnc             -12.667             0.00  \n",
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      choice   No. Observations:                4,933\n",
      "Model:             Multinomial Logit Model   Df Residuals:                    4,920\n",
      "Method:                                MLE   Df Model:                           13\n",
      "Date:                     Mon, 06 Nov 2023   Pseudo R-squ.:                   0.349\n",
      "Time:                             13:26:01   Pseudo R-bar-squ.:               0.347\n",
      "AIC:                            12,526.424   Log-Likelihood:             -6,250.212\n",
      "BIC:                            12,610.972   LL-Null:                    -9,595.283\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Walk ASC        -0.3049      0.113     -2.687      0.007      -0.527      -0.083\n",
      "Bike ASC        -2.6876      0.137    -19.578      0.000      -2.957      -2.419\n",
      "HOV2 ASC        -0.5853      0.132     -4.428      0.000      -0.844      -0.326\n",
      "HOV3+ ASC       -2.7673      0.283     -9.795      0.000      -3.321      -2.214\n",
      "Transit ASC     -1.3113      0.093    -14.071      0.000      -1.494      -1.129\n",
      "TNC             -2.3800      0.302     -7.870      0.000      -2.973      -1.787\n",
      "time walk       -0.0451      0.002    -24.666      0.000      -0.049      -0.042\n",
      "time bike       -0.0611      0.004    -15.101      0.000      -0.069      -0.053\n",
      "time sov        -0.1668      0.010    -17.524      0.000      -0.185      -0.148\n",
      "time hov2       -0.2398      0.012    -19.984      0.000      -0.263      -0.216\n",
      "time hov3       -0.2070      0.019    -11.094      0.000      -0.244      -0.170\n",
      "time transit    -0.0955      0.005    -19.704      0.000      -0.105      -0.086\n",
      "time tnc        -0.2409      0.021    -11.254      0.000      -0.283      -0.199\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# In this case, there are now 13 coefficients we are estimated. Count the values in the \"names\" list, including ASCs and other coefficents\n",
    "model_2.fit_mle(np.zeros(13))\n",
    "print(np.round(model_2.summary, 3))   # Make things easier to read\n",
    "\n",
    "# Look at the estimation results\n",
    "print(model_2.get_statsmodels_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood ratio test\n",
    "The unrestricted model is the one defined above (Model 2). We are not constraining $\\beta(time)$ to be equal across all modes as in the first model. Generally the unrestricted model is the one with more coefficients.\n",
    "\n",
    "The restricted model for comparison is Model 1. We want to perform the likelihood ratio test to see if there is a statistically significant difference between the specifications. If so, we can reject the null hypothesis and accept the alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of Parameters                                                      7\n",
       "Number of Observations                                                 4933\n",
       "Null Log-Likelihood                                            -9595.282945\n",
       "Fitted Log-Likelihood                                           -6436.40759\n",
       "Rho-Squared                                                        0.329211\n",
       "Rho-Bar-Squared                                                    0.328482\n",
       "Estimation Message        Desired error not necessarily achieved due to ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can look at fit statistics using this command\n",
    "model_1.fit_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372.39089121257894"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL_restricted =  model_1.fit_summary[3]     # -6436.408, Model 1\n",
    "LL_unrestricted = model_2.fit_summary[3]    # -6250.212, Model 2\n",
    "\n",
    "-2*(LL_restricted-LL_unrestricted)    # See slides posted for this formula or the link to Koppelman and Bhat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio test returns a value of 372.39. If this value is creater than the chi-square critical value, we can reject the null hypothesis. The degrees of freedom to consider for the chi-square distribution is the difference in coefficients between the two models, or 6 in this example (13 - 7). This value is far higher than the critical chi-square value at a 99.9% confidence level, so we can say that travel time coefficients provide a better measure of utility when defined for all modes separately. Given the large t-statistic for all coefficients (and intuitive signs), we will keep all variables and use this model going forward.\n",
    "\n",
    "Chi-square table: https://faculty.washington.edu/heagerty/Books/Biostatistics/TABLES/ChiSquare/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping time coefficients\n",
    "An alternative to above is grouping time coefficients across somewhat similar modes. We will group non-motorized modes together ($\\beta(time_{nmt})$), as well as auto modes ($\\beta(time_{auto})$). Transit and TNC will have their own time coefficients. The utility formulation for this is:\n",
    "- $V(walk) = ASC_{walk} + \\beta(time_{nmt}) * TTime_{walk}$\n",
    "- $V(bike) = ASC_{bike} + \\beta(time_{nmt}) * TTime_{bike}$\n",
    "- $V(hov2) = ASC_{hov2} + \\beta(time_{auto}) * TTime_{hov2}$\n",
    "- $V(hov3) = ASC_{hov3} + \\beta(time_{auto}) * TTime_{hov3}$\n",
    "- $V(transit) = ASC_{transit} + \\beta(time_{transit}) * TTime_{transit}$\n",
    "- $V(tnc) = ASC_{tnc} + \\beta(time_{tnc}) * TTime_{tnc}$\n",
    "- $V(sov) = \\beta(time_{auto}) * TTime_{sov}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using what is called an Ordered Dictionary\n",
    "# Remember that a dictionary looks like this {'key': 'value'}\n",
    "# An ordered dictionary is a special version of this type that keeps the keys in order\n",
    "\n",
    "specification = OrderedDict()\n",
    "names = OrderedDict()\n",
    "\n",
    "# Define the alternative specific constants (ASCs), i.e., the intercepts\n",
    "# Remember that one choice is the baseline (ASC=0)\n",
    "# Leave the chosen baseline mode out of the list of intercept values below\n",
    "# In this case, we are using SOV as the base model - it's common to use the most likely alternative as the base\n",
    "specification[\"intercept\"] = [1, 2, 4, 5, 6, 9]    # these are the mode IDs, excluding 3 for SOV\n",
    "names['intercept'] = ['Walk ASC','Bike ASC', 'HOV2 ASC','HOV3+ ASC','Transit ASC', 'TNC']    # Provide labels\n",
    "\n",
    "# we will have 4 separate groups. If a group has multiple values it is placed in its own list\n",
    "specification['travtime'] = [[1,2],[3,4,5],6,9]    # Note that this is a list inside a list [[]]\n",
    "names['travtime'] = ['time walk and bike','time auto','time transit','time tnc']\n",
    "\n",
    "# Specify which columns are used in the estimation\n",
    "custom_alt_id = \"mode_id\"    # Mode columns, must be integer based\n",
    "obs_id_column = \"custom_id\"    # an ID that is unique to each choice (a set of chosen and unchosen alternatives have their own ID)\n",
    "choice_column = \"choice\"    # 0/1 column indicating if that row was the chosen or unchosen alternative\n",
    "\n",
    "# Call the module to create the choice model specification\n",
    "model_1 = pl.create_choice_model(data=df_hbw,    # Note that here's we are specifying the df_hbw dataset\n",
    "                                alt_id_col=custom_alt_id,\n",
    "                                obs_id_col=obs_id_column,\n",
    "                                choice_col=choice_column,\n",
    "                                specification=specification,    # using the basic_specification from above\n",
    "                                model_type=\"MNL\",\n",
    "                                names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -9,595.2829\n",
      "Initial Log-likelihood: -9,595.2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaitlynng/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:527: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  warn('Method %s does not use Hessian information (hess).' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.46 seconds.\n",
      "Final log-likelihood: -6,306.7316\n",
      "                    parameters  std_err  t_stats  p_values  robust_std_err  \\\n",
      "Walk ASC                -0.274    0.097   -2.836     0.005           0.123   \n",
      "Bike ASC                -3.043    0.128  -23.773     0.000           0.151   \n",
      "HOV2 ASC                -1.738    0.054  -32.001     0.000           0.054   \n",
      "HOV3+ ASC               -3.437    0.119  -28.900     0.000           0.119   \n",
      "Transit ASC             -1.384    0.087  -15.935     0.000           0.118   \n",
      "TNC                     -2.559    0.301   -8.513     0.000           0.232   \n",
      "time walk and bike      -0.047    0.002  -25.799     0.000           0.005   \n",
      "time auto               -0.162    0.009  -18.784     0.000           0.014   \n",
      "time transit            -0.089    0.004  -19.951     0.000           0.007   \n",
      "time tnc                -0.226    0.021  -10.769     0.000           0.019   \n",
      "\n",
      "                    robust_t_stats  robust_p_values  \n",
      "Walk ASC                    -2.235            0.025  \n",
      "Bike ASC                   -20.121            0.000  \n",
      "HOV2 ASC                   -32.004            0.000  \n",
      "HOV3+ ASC                  -28.899            0.000  \n",
      "Transit ASC                -11.733            0.000  \n",
      "TNC                        -11.008            0.000  \n",
      "time walk and bike         -10.431            0.000  \n",
      "time auto                  -11.523            0.000  \n",
      "time transit               -13.543            0.000  \n",
      "time tnc                   -11.972            0.000  \n",
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      choice   No. Observations:                4,933\n",
      "Model:             Multinomial Logit Model   Df Residuals:                    4,923\n",
      "Method:                                MLE   Df Model:                           10\n",
      "Date:                     Mon, 06 Nov 2023   Pseudo R-squ.:                   0.343\n",
      "Time:                             13:26:03   Pseudo R-bar-squ.:               0.342\n",
      "AIC:                            12,633.463   Log-Likelihood:             -6,306.732\n",
      "BIC:                            12,698.500   LL-Null:                    -9,595.283\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Walk ASC              -0.2741      0.097     -2.836      0.005      -0.464      -0.085\n",
      "Bike ASC              -3.0432      0.128    -23.773      0.000      -3.294      -2.792\n",
      "HOV2 ASC              -1.7378      0.054    -32.001      0.000      -1.844      -1.631\n",
      "HOV3+ ASC             -3.4367      0.119    -28.900      0.000      -3.670      -3.204\n",
      "Transit ASC           -1.3836      0.087    -15.935      0.000      -1.554      -1.213\n",
      "TNC                   -2.5588      0.301     -8.513      0.000      -3.148      -1.970\n",
      "time walk and bike    -0.0470      0.002    -25.799      0.000      -0.051      -0.043\n",
      "time auto             -0.1625      0.009    -18.784      0.000      -0.179      -0.146\n",
      "time transit          -0.0889      0.004    -19.951      0.000      -0.098      -0.080\n",
      "time tnc              -0.2264      0.021    -10.769      0.000      -0.268      -0.185\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Note we now have 10 coefficients to be estimated\n",
    "model_1.fit_mle(np.zeros(10))\n",
    "print(np.round(model_1.summary, 3))    # Make things easier to read\n",
    "\n",
    "# Look at the estimation results\n",
    "print(model_1.get_statsmodels_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to html \"Lab 4 In Class.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
